package com.spark.scala

import org.apache.spark.sql.SparkSession
//import org.apache.spark.sql.{SparkSession,types}

case class Person1(Product:String,Amount:Int,Country:String)
object Pivot_Example {

  def main(args: Array[String]):Unit ={
    val spark = SparkSession.builder().master("local").appName("WindowDFFunc").getOrCreate()
    import spark.implicits._//to use DF()
    val pivot = spark.sparkContext
      .textFile("C://Users//sashirekha.bisati//Desktop//pivot_data.txt")
      .map(_.split(","))
      .map(attributes => Person1(attributes(0),attributes(1).trim.toInt,attributes(2)))
      .toDF()
    pivot.createOrReplaceTempView("pivotdata")
    val pivotdata = spark.sql("select Product,Country,Amount from pivotdata")
    pivotdata.show()
    val pivotDF = pivot.groupBy("Product").pivot("Country").sum("Amount")
    pivotDF.show()
  }
}
