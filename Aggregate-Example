package com.spark.scala

import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions._
case class Sales(Name:String,Dept:String,salary:Int)
object Aggeragate_Example {

  def main(args: Array[String]):Unit ={
  val spark = SparkSession.builder().master("local").appName("Aggeragate").getOrCreate()

  import spark.implicits._//to use DF()
  val simpleData = spark.sparkContext
    .textFile("C://Users//sashirekha.bisati//Desktop//sales_data.txt")
    .map(_.split(","))
    .map(attributes => Sales(attributes(0),attributes(1),attributes(2).trim.toInt))
    .toDF()
  simpleData.createOrReplaceTempView("sales_data")
  println("approx_count_distinct: "+ simpleData.select(approx_count_distinct("salary")).collect()(0)(0))


}
}
